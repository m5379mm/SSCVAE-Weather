import torch
import torch.nn as nn
from torch.nn import functional as F

import numpy as np
import math
from geomloss import SamplesLoss
from enhanced_losses import EnhancedReconstructionLoss
# æ³¨æ„åŠ›æœºåˆ¶çš„ç¼–ç å™¨-è§£ç å™¨ï¼Œå¹¶å¼•å…¥äº†LISTAç”¨äºŽç¨€ç–ç¼–ç çš„è§£ç éƒ¨åˆ†

# é€šé“æ³¨æ„åŠ›æœºåˆ¶ï¼šé€šè¿‡å…¨å±€å¹³å‡æ± åŒ–å’Œæœ€å¤§æ± åŒ–æ¥æå–æ¯ä¸ªé€šé“çš„å…¨å±€ä¿¡æ¯ï¼Œç„¶åŽé€šè¿‡ä¸€ç³»åˆ—å…¨è¿žæŽ¥å±‚ç”Ÿæˆé€šé“æ³¨æ„åŠ›æƒé‡ï¼Œæœ€ç»ˆï¼Œè¾“å…¥ç‰¹å¾å›¾ä¸Žè¿™äº›æƒé‡ç›¸ä¹˜ï¼Œä»¥å¼ºè°ƒé‡è¦çš„é€šé“ç‰¹å¾ã€‚
class ChannelAttention(nn.Module):
    def __init__(self,
                 in_channels,
                 reduction):
        super(ChannelAttention, self).__init__()
        self._avg_pool = nn.AdaptiveAvgPool2d(1) # å…¨å±€å¹³å‡æ± åŒ–
        self._max_pool = nn.AdaptiveMaxPool2d(1) # æœ€å¤§æ± åŒ–
        self._fc = nn.Sequential( # ä¸¤å±‚çš„å…¨è¿žæŽ¥å±‚ï¼Œç”¨äºŽç”Ÿæˆé€šé“æ³¨æ„åŠ›æƒé‡
            nn.Linear(in_channels, in_channels // reduction, bias=False),
            nn.ReLU(),
            nn.Linear(in_channels // reduction, in_channels, bias=False),
        )
        self._sigmoid = nn.Sigmoid() # æ¿€æ´»å‡½æ•°ï¼Œæ˜ å°„åˆ°[0,1]
    
    def forward(self, x):
        b, c, _, _ = x.size()
        avgOut = self._fc(self._avg_pool(x).view(b, c))  # [B, C, H, W] -> [B, C, 1, 1] -> [B, C]
        maxOut = self._fc(self._max_pool(x).view(b, c))  # [B, C, H, W] -> [B, C, 1, 1] -> [B, C]
        y = self._sigmoid(avgOut + maxOut).view(b, c, 1, 1)  # [B, C] -> [B, C, 1, 1]
        out = x * y.expand_as(x)  # [B, C, H, W]
        return out

# ç©ºé—´æ³¨æ„åŠ›
class SpatialAttention(nn.Module):
    def __init__(self,
                 kernel_size):
        super(SpatialAttention, self).__init__()
        self._conv = nn.Conv2d(in_channels=2,
                               out_channels=1,
                               kernel_size=kernel_size,
                               stride=1,
                               padding=(kernel_size - 1) // 2,
                               bias=False)
        self._sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        b, _, h, w = x.size()
        avgOut = torch.mean(x, dim=1, keepdim=True)  # [B, C, H, W] -> [B, 1, H, W]
        maxOut, _ = torch.max(x, dim=1, keepdim=True)  # [B, C, H, W] -> [B, 1, H, W]
        y = torch.cat([avgOut, maxOut], dim=1)  # [B, 2, H, W]
        y = self._sigmoid(self._conv(y))  # [B, 2, H, W] -> [B, 1, H, W]
        out = x * y.expand_as(x)  # [B, C, H, W]
        return out


class CBAM(nn.Module):
    def __init__(self,
                 in_channels,
                 reduction,
                 kernel_size):
        super(CBAM, self).__init__()
        self.ChannelAtt = ChannelAttention(in_channels, reduction)
        self.SpatialAtt = SpatialAttention(kernel_size)
    
    def forward(self, x):
        x = self.ChannelAtt(x)  # [B, C, H, W]
        x = self.SpatialAtt(x)  # [B, C, H, W]
        return x

# æ®‹å·®å— ä½¿ç”¨äº†ä¸¤ä¸ªå·ç§¯å±‚ï¼Œå¹¶é€šè¿‡è·³è·ƒè¿žæŽ¥å°†è¾“å…¥ç›´æŽ¥åŠ åˆ°è¾“å‡ºä¸Šã€‚è¿™æ ·å¯ä»¥ç¼“è§£æ·±å±‚ç¥žç»ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¹¶åŠ é€Ÿè®­ç»ƒã€‚
class ResidualBlock(nn.Module):
    def __init__(self,
                 in_channels,
                 hid_channels):
        super(ResidualBlock, self).__init__()
        
        self._block = nn.Sequential(
            nn.ReLU(),
            nn.Conv2d(in_channels=in_channels,
                      out_channels=hid_channels,
                      kernel_size=3, stride=1, padding=1, bias=False),
            nn.ReLU(),
            nn.Conv2d(in_channels=hid_channels,
                      out_channels=in_channels,
                      kernel_size=1, stride=1, bias=False)
        )
    
    def forward(self, x):
        return x + self._block(x) # å°†è¾“å…¥ç›´æŽ¥åŠ åˆ°ç»è¿‡ä¸€ç³»åˆ—å·ç§¯å’Œæ¿€æ´»å‡½æ•°å¤„ç†åŽçš„è¾“å‡ºä¸Š

# ä¸‹é‡‡æ ·æ“ä½œ
class DownSampleBlock(nn.Module):
    def __init__(self,
                 in_channels,
                 out_channels):
        super(DownSampleBlock, self).__init__()

        self._block = nn.Sequential(
            nn.Conv2d(in_channels=in_channels,
                      out_channels=out_channels,
                      kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels), # æ‰¹é‡å½’ä¸€åŒ–ï¼Ÿï¼Ÿï¼Ÿ
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
    
    def forward(self, x):
        return self._block(x)

#ä¸Šé‡‡æ ·æ“ä½œ 
class UpSampleBlock(nn.Module):
    def __init__(self,
                 in_channels,
                 out_channels):
        super(UpSampleBlock, self).__init__()

        self._block = nn.Sequential(
            nn.ConvTranspose2d(in_channels=in_channels,
                               out_channels=out_channels,
                               kernel_size=2, stride=2),# åå·ç§¯ï¼Ÿï¼Ÿï¼Ÿ
            nn.Conv2d(in_channels=out_channels,
                      out_channels=out_channels,
                      kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU()
        )
    
    def forward(self, x):
        return self._block(x)

# æ¿€æ´»å‡½æ•°
class Swish(nn.Module):
    def __init__(self):
        super(Swish, self).__init__()
    def forward(self, x):
        return x * torch.sigmoid(x)

# éžå±€éƒ¨æ³¨æ„åŠ›å—ï¼šæ•æ‰å…¨å±€ä¾èµ–å…³ç³»ã€‚é€šè¿‡è®¡ç®—è¾“å…¥ç‰¹å¾çš„è‡ªç›¸å…³çŸ©é˜µæ¥ç”Ÿæˆå…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°åŽŸå§‹è¾“å…¥ç‰¹å¾ä¸Šã€‚
class NonLocalBlock(nn.Module):
    def __init__(self,
                 in_channels,
                 hid_channels):
        super(NonLocalBlock, self).__init__()

        self.hid_channels = hid_channels
        self._conv_theta = nn.Conv2d(in_channels=in_channels,
                                     out_channels=hid_channels,
                                     kernel_size=1, stride=1, padding=0, bias=False)
        self._conv_phi = nn.Conv2d(in_channels=in_channels,
                                   out_channels=hid_channels,
                                   kernel_size=1, stride=1, padding=0, bias=False)
        self._conv_g = nn.Conv2d(in_channels=in_channels,
                                 out_channels=hid_channels,
                                 kernel_size=1, stride=1, padding=0, bias=False)
        self._soft_max = nn.Softmax(dim=1)
        self._conv_mask = nn.Conv2d(in_channels=hid_channels,
                                    out_channels=in_channels,
                                    kernel_size=1, stride=1, padding=0, bias=False)

    def forward(self, x):
        b, c, h, w = x.size()

        # [B, C, H, W] -> [B, C', HW] -> [B, HW, C']
        theta = self._conv_theta(x).view(b, self.hid_channels, -1).permute(0, 2, 1).contiguous()
        # [B, C, H, W] -> [B, C', HW]
        phi = self._conv_phi(x).view(b, self.hid_channels, -1)
        # [B, C, H, W] -> [B, C', HW] -> [B, HW, C']
        g = self._conv_g(x).view(b, self.hid_channels, -1).permute(0, 2, 1).contiguous()
        # [B, HW, C'] * [B, C', HW] = [B, HW, HW]
        mul_theta_phi = self._soft_max(torch.matmul(theta, phi))
        # [B, HW, HW] * [B, HW, C'] = [B, HW, C']
        mul_theta_phi_g = torch.matmul(mul_theta_phi, g)
        # [B, HW, C'] -> [B, C', HW] -> [B, C', H, W]
        mul_theta_phi_g = mul_theta_phi_g.permute(0, 2, 1).contiguous().view(b, self.hid_channels, h, w)
        # [B, C', H, W] -> [B, C, H, W]
        mask = self._conv_mask(mul_theta_phi_g)

        return x + mask


class Encoder(nn.Module):
    def __init__(self,
                 in_channels,
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,
                 down_samples,
                 num_groups):
        super(Encoder, self).__init__()

        # [B, C, H, W] -> [B, C', H, W]
        self._conv_1 = nn.Conv2d(in_channels=in_channels,
                                 out_channels=hid_channels_1,
                                 kernel_size=3, stride=1, padding=1)
        
        # [B, C', H, W] -> [B, C'', h, w]
        self._down_samples = nn.ModuleList()
        for i in range(down_samples):
            cur_in_channels = hid_channels_1 if i == 0 else hid_channels_2
            self._down_samples.append(
                ResidualBlock(in_channels=cur_in_channels,
                              hid_channels=cur_in_channels // 2)
            )
            self._down_samples.append(
                DownSampleBlock(in_channels=cur_in_channels,
                                out_channels=hid_channels_2)
            )

        # [B, C'', h, w] -> [B, C'', h, w]
        self._res_1 = ResidualBlock(in_channels=hid_channels_2,
                                    hid_channels=hid_channels_2 // 2)
        self._non_local = NonLocalBlock(in_channels=hid_channels_2,
                                        hid_channels=hid_channels_2 // 2)
        self._res_2 = ResidualBlock(in_channels=hid_channels_2,
                                    hid_channels=hid_channels_2 // 2)
        
        self._group_norm = nn.GroupNorm(num_groups=num_groups,
                                        num_channels=hid_channels_2)
        self._swish = Swish()

        # [B, C'', h, w] -> [B, n, h, w]
        self._conv_2 = nn.Conv2d(in_channels=hid_channels_2,
                                 out_channels=out_channels,
                                 kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = self._conv_1(x)

        for layer in self._down_samples:
            x = layer(x)

        x = self._res_1(x)
        x = self._non_local(x)
        x = self._res_2(x)

        x = self._group_norm(x)
        x = self._swish(x)
        x = self._conv_2(x)

        return x


class Decoder(nn.Module):
    def __init__(self,
                 in_channels,
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,
                 up_samples,
                 num_groups):
        super(Decoder, self).__init__()

        # [B, n, h, w] -> [B, C'', h, w]
        self._conv_1 = nn.Conv2d(in_channels=out_channels,
                                 out_channels=hid_channels_2,
                                 kernel_size=3, stride=1, padding=1)

        # [B, C'', h, w] -> [B, C'', h, w]
        self._res_1 = ResidualBlock(in_channels=hid_channels_2,
                                    hid_channels=hid_channels_2 // 2)
        self._non_local = NonLocalBlock(in_channels=hid_channels_2,
                                        hid_channels=hid_channels_2 // 2)
        self._res_2 = ResidualBlock(in_channels=hid_channels_2,
                                    hid_channels=hid_channels_2 // 2)
        
        # [B, C'', h, w] -> [B, C', H, W]
        self._up_samples = nn.ModuleList()
        for i in range(up_samples):
            cur_in_channels = hid_channels_2 if i == 0 else hid_channels_1
            self._up_samples.append(
                ResidualBlock(in_channels=cur_in_channels,
                              hid_channels=cur_in_channels // 2)
            )
            self._up_samples.append(
                UpSampleBlock(in_channels=cur_in_channels,
                              out_channels=hid_channels_1)
            )
        
        # [B, C', H, W] -> [B, C', H, W]
        self._group_norm = nn.GroupNorm(num_groups=num_groups,
                                        num_channels=hid_channels_1)
        self._swish = Swish()

        # [B, C', H, W] -> [B, C, H, W]
        self._conv_2 = nn.Conv2d(in_channels=hid_channels_1,
                                 out_channels=in_channels,
                                 kernel_size=3, stride=1, padding=1)
        
    def forward(self, x):
        #print('*')
        x = self._conv_1(x)
        #print('/')
        x = self._res_1(x)
        x = self._non_local(x)
        x = self._res_2(x)

        for layer in self._up_samples:
            x = layer(x)

        x = self._group_norm(x)
        x = self._swish(x)
        x = self._conv_2(x)

        return x

# DCTå­—å…¸åˆå§‹åŒ–ï¼šå»ºç«‹ä¸€ä¸ªè¶…å®Œå¤‡çš„DCTå­—å…¸
def init_dct(n, m):  # n, m
    """ Compute the Overcomplete Discrete Cosinus Transform. """
    oc_dictionary = np.zeros((n, m))
    for k in range(m):
        V = np.cos(np.arange(0, n) * k * np.pi / m)  
        if k > 0:
            V = V - np.mean(V)
        oc_dictionary[:, k] = V / np.linalg.norm(V)  
    oc_dictionary = np.kron(oc_dictionary, oc_dictionary)   
    oc_dictionary = oc_dictionary.dot(np.diag(1 / np.sqrt(np.sum(oc_dictionary ** 2, axis=0))))  
    idx = np.arange(0, n ** 2)  
    idx = idx.reshape(n, n, order="F")  
    idx = idx.reshape(n ** 2, order="C") 
    oc_dictionary = oc_dictionary[idx, :]
    oc_dictionary = torch.from_numpy(oc_dictionary).float()
    return oc_dictionary  # n**2, m**2

#ç¨€ç–ç¼–ç çš„è¿­ä»£ç®—æ³•
class LISTA(nn.Module):
    def __init__(self,
                 num_atoms,
                 num_dims,
                 num_iters,
                 h,
                 w,
                 device):
        super(LISTA, self).__init__()

        self._num_atoms = num_atoms
        self._num_dims = num_dims
        self._device = device

        self._Dict = nn.Parameter(self.initialize_dct_weights())  # [D, K]
        self._L = nn.Parameter((torch.norm(self._Dict, p=2)) ** 2)  # scalar
        one = torch.ones(h, w)
        one = torch.unsqueeze(one, 0)
        one = torch.unsqueeze(one, -1)  # [1, h, w, 1]
        self._alpha = nn.Parameter(one)

        self._Zero = torch.zeros(num_atoms).to(device)  # [K]
        self._Identity = torch.eye(num_atoms).to(device)  # [K, K]

        self._num_iters = num_iters
    
    def initialize_dct_weights(self):
        n = math.ceil(math.sqrt(self._num_dims))
        m = math.ceil(math.sqrt(self._num_atoms))
        weights = init_dct(n, m)[:, :self._num_atoms]  # [D, K]
        
        return weights

    def soft_thresh(self, x, theta):
        return torch.sign(x) * torch.max(torch.abs(x) - theta, self._Zero)

    def generation(self, input_z):
        input_z = input_z.permute(0, 2, 3, 1).contiguous()  # [B, K, H, W] -> [B, H, W, K]
        x_recon = torch.matmul(input_z, self._Dict.t())  # [B, H, W, K] * [K, D] -> [B, H, W, D]
        x_recon = x_recon.permute(0, 3, 1, 2).contiguous()  # [B, H, W, D] -> [B, D, H, W]
        return x_recon

    def forward(self, x):
        l = self._alpha / self._L  # scalar

        x = x.permute(0, 2, 3, 1).contiguous()  # [B, D, H, W] -> [B, H, W, D]

        S = self._Identity - (1 / self._L) * self._Dict.t().mm(self._Dict)  # [K, K]
        S = S.t()  # [K, K]

        y = torch.matmul(x, self._Dict)  # [B, H, W, D] * [D, K] -> [B, H, W, K]

        z = self.soft_thresh(y, l)  # [B, H, W, K]
        for t in range(self._num_iters):
            z = self.soft_thresh(torch.matmul(z, S) + (1 / self._L) * y, l)

        x_recon = torch.matmul(z, self._Dict.t())  # [B, H, W, K] * [K, D] -> [B, H, W, D]

        z = z.permute(0, 3, 1, 2).contiguous()  # [B, H, W, K] -> [B, K, H, W]
        x_recon = x_recon.permute(0, 3, 1, 2).contiguous()  # [B, H, W, D] -> [B, D, H, W]

        return z, x_recon, self._Dict


# æ—¶é—´æ³¨æ„åŠ›æ¨¡å—ï¼šå¯¹å¤šå¸§åºåˆ—åœ¨æ—¶é—´ç»´åº¦ä¸Šè¿›è¡ŒåŠ æƒ
class TemporalAttention(nn.Module):
    def __init__(self, num_steps, channels=None):
        super().__init__()
        self.num_steps = num_steps
        
        # å¢žå¼ºç‰ˆï¼šä½¿ç”¨å·ç§¯ç½‘ç»œå­¦ä¹ æ—¶åºä¾èµ–
        if channels is None:
            # ç®€åŒ–ç‰ˆï¼šä»…ä½¿ç”¨å¯å­¦ä¹ çš„æƒé‡å‘é‡
            self.attn = nn.Parameter(torch.randn(1, num_steps, 1, 1, 1))  # [1, T, 1, 1, 1]
            self.use_conv = False
        else:
            # å¢žå¼ºç‰ˆï¼šä½¿ç”¨1Då·ç§¯å­¦ä¹ æ—¶åºæ¨¡å¼
            self.use_conv = True
            self.temporal_conv = nn.Sequential(
                nn.Conv3d(channels, channels // 4, kernel_size=(3, 1, 1), padding=(1, 0, 0), groups=1),
                nn.BatchNorm3d(channels // 4),
                nn.ReLU(),
                nn.Conv3d(channels // 4, 1, kernel_size=(3, 1, 1), padding=(1, 0, 0)),
            )
        
        self.softmax = nn.Softmax(dim=1)  # softmax åœ¨æ—¶é—´ç»´åº¦

    def forward(self, x):  # x: [B, T, C, H, W]
        if self.use_conv:
            # å¢žå¼ºç‰ˆï¼šé€šè¿‡å·ç§¯å­¦ä¹ æ—¶åºæ³¨æ„åŠ›
            B, T, C, H, W = x.size()
            x_perm = x.permute(0, 2, 1, 3, 4)  # [B, C, T, H, W]
            attn_logits = self.temporal_conv(x_perm)  # [B, 1, T, H, W]
            attn_logits = attn_logits.permute(0, 2, 1, 3, 4)  # [B, T, 1, H, W]
            attn_scores = self.softmax(attn_logits)  # [B, T, 1, H, W]
            x_attended = x * attn_scores.expand_as(x)  # [B, T, C, H, W]
        else:
            # ç®€åŒ–ç‰ˆï¼šä½¿ç”¨å¯å­¦ä¹ æƒé‡
            attn_scores = self.attn.expand(x.size(0), -1, x.size(2), x.size(3), x.size(4))  # [B, T, C, H, W]
            attn_scores = self.softmax(attn_scores)  # [B, T, C, H, W]
            x_attended = x * attn_scores  # [B, T, C, H, W]
        
        return x_attended


class AttentiveLISTA(nn.Module):
    def __init__(self,
                 num_atoms,
                 num_dims,
                 num_iters,
                 device,
                 use_time_attention=False):  # æ·»åŠ å‚æ•°æŽ§åˆ¶æ˜¯å¦ä½¿ç”¨æ—¶é—´æ³¨æ„åŠ›
        super(AttentiveLISTA, self).__init__()

        self._num_atoms = num_atoms
        self._num_dims = num_dims
        self._device = device
        self.use_time_attention = use_time_attention

        self._Dict = nn.Parameter(self.initialize_dct_weights())  # [D, K]
        self._L = nn.Parameter((torch.norm(self._Dict, p=2)) ** 2)  # scalar
        self._conv = nn.Conv2d(in_channels=num_dims,
                               out_channels=num_atoms,
                               kernel_size=3, stride=1, padding=1)
        self._res1 = ResidualBlock(in_channels=num_atoms,
                                   hid_channels=num_atoms//2)
        self._res2 = ResidualBlock(in_channels=num_atoms,
                                   hid_channels=num_atoms//2)
        self._cbam = CBAM(in_channels=num_atoms,
                          reduction=16,
                          kernel_size=3)

        self._Zero = torch.zeros(num_atoms).to(device)  # [K]
        self._Identity = torch.eye(num_atoms).to(device)  # [K, K]

        # æ·»åŠ æ—¶é—´æ³¨æ„åŠ›æ¨¡å—
        if self.use_time_attention:
            # âœ… ä½¿ç”¨å¢žå¼ºç‰ˆï¼šä¼ å…¥ channels å‚æ•°ä»¥å¯ç”¨å·ç§¯æ³¨æ„åŠ›
            # è¿™é‡Œ num_dims æ˜¯æ½œåœ¨ç©ºé—´çš„é€šé“æ•°
            self._time_attention = TemporalAttention(num_steps=1, channels=num_atoms)

        self._num_iters = num_iters
    
    # def initialize_dct_weights(self):
    #     weights = torch.zeros(self._num_atoms, self._num_dims).to(self._device)  # [K, D]
    #     for i in range(self._num_atoms):
    #         atom = torch.cos((2 * torch.arange(self._num_dims) + 1) * i * (3.141592653589793 / (2 * self._num_dims)))# * math.sqrt(2 / self._num_dims)
    #         weights[i, :] = atom / torch.norm(atom, p=2)
    #     return weights.t()  # [D, K]
    
    def initialize_dct_weights(self):
        n = math.ceil(math.sqrt(self._num_dims))
        m = math.ceil(math.sqrt(self._num_atoms))
        weights = init_dct(n, m)[:, :self._num_atoms]  # [D, K]
        
        return weights
    
    def get_dict(self):
        return self._Dict
    
    def set_dict(self, dictionary):
        self._Dict= nn.Parameter(dictionary)
        print("Dictionary initialized with pretrained values.")

    def soft_thresh(self, x, theta):
        return torch.sign(x) * torch.max(torch.abs(x) - theta, self._Zero)

    def generation(self, input_z):
        input_z = input_z.permute(0, 2, 3, 1).contiguous()  # [B, K, H, W] -> [B, H, W, K]
        x_recon = torch.matmul(input_z, self._Dict.t())  # [B, H, W, K] * [K, D] -> [B, H, W, D]
        x_recon = x_recon.permute(0, 3, 1, 2).contiguous()  # [B, H, W, D] -> [B, D, H, W]
        return x_recon

    def forward(self, x):
        # è¾“å…¥ä¿è¯æ˜¯ [B, T, D, H, W]
        B, T, D, H, W = x.size()
        x = x.view(B * T, D, H, W)  # å±•å¹³æ—¶é—´ç»´åº¦
        
        l = self._conv(x)  # [B*T, D, H, W] -> [B*T, K, H, W]
        l = self._res1(l)
        l = self._res2(l)
        
        # æ—¶é—´æ³¨æ„åŠ›ï¼šæ¢å¤æ—¶é—´ç»´åº¦åŽåº”ç”¨
        if self.use_time_attention:
            _, K, _, _ = l.size()
            l = l.view(B, T, K, H, W)  # [B, T, K, H, W]
            self._time_attention.num_steps = T
            l = self._time_attention(l)  # [B, T, K, H, W]
            l = l.view(B * T, K, H, W)  # å†å±•å¹³
        
        l = self._cbam(l) / self._L

        l = l.permute(0, 2, 3, 1).contiguous()  # [B*T, K, H, W] -> [B*T, H, W, K]
        x = x.permute(0, 2, 3, 1).contiguous()  # [B*T, D, H, W] -> [B*T, H, W, D]
        
        S = self._Identity - (1 / self._L) * self._Dict.t().mm(self._Dict)  # [K, K]
        S = S.t()  # [K, K]

        y = torch.matmul(x, self._Dict)  # [B*T, H, W, D] * [D, K] -> [B*T, H, W, K]

        z = self.soft_thresh(y, l)  # [B*T, H, W, K]
        for t in range(self._num_iters):
            z = self.soft_thresh(torch.matmul(z, S) + (1 / self._L) * y, l)

        x_recon = torch.matmul(z, self._Dict.t())  # [B*T, H, W, K] * [K, D] -> [B*T, H, W, D]

        z = z.permute(0, 3, 1, 2).contiguous()  # [B*T, H, W, K] -> [B*T, K, H, W]
        x_recon = x_recon.permute(0, 3, 1, 2).contiguous()  # [B*T, H, W, D] -> [B*T, D, H, W]
        
        # æ¢å¤æ—¶é—´ç»´åº¦
        z = z.view(B, T, -1, H, W)  # [B, T, K, H, W]
        x_recon = x_recon.view(B, T, -1, H, W)  # [B, T, D, H, W]

        return z, x_recon, self._Dict

class GroupConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups, act_norm=False):
        super(GroupConv2d, self).__init__()
        self.act_norm = act_norm
        if in_channels % groups != 0:
            groups = 1
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,groups=groups)
        self.norm = nn.GroupNorm(groups,out_channels)
        self.activate = nn.LeakyReLU(0.2, inplace=True)
    
    def forward(self, x):
        y = self.conv(x)
        if self.act_norm:
            y = self.activate(self.norm(y))
        return y
# class Residual(nn.Module):
#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1,
#                  dropout_p=0.0, norm='bn', groups=8, padding_mode='reflect'):
#         super().__init__()
#         Norm = (lambda c: nn.GroupNorm(groups, c)) if norm=='gn' else (lambda c: nn.BatchNorm2d(c))
#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,
#                                bias=False, padding_mode=padding_mode)
#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding,
#                                bias=False, padding_mode=padding_mode)
#         self.n1 = Norm(out_channels)
#         self.n2 = Norm(out_channels)
#         self.act = nn.GELU()
#         self.drop_p = dropout_p

#         self.match = (nn.Sequential(
#             nn.Conv2d(in_channels, out_channels, 1, bias=False),
#             Norm(out_channels)
#         ) if in_channels != out_channels else nn.Identity())

#     def forward(self, x):
#         r = x
#         x = self.act(self.n1(self.conv1(x)))
#         if self.drop_p > 0: x = F.dropout2d(x, p=self.drop_p, training=self.training)
#         x = self.n2(self.conv2(x))
#         if self.drop_p > 0: x = F.dropout2d(x, p=self.drop_p, training=self.training)
#         x = self.act(x + self.match(r))
#         return x


class TranslatorWithResidual0(nn.Module):
    def __init__(self, C_in, C_hid, C_out, incep_ker=[3,5,7],
                 norm='bn', groups=8, dropout_p=0.0, padding_mode='reflect'):
        super().__init__()
        Norm = (lambda c: nn.GroupNorm(groups, c)) if norm=='gn' else (lambda c: nn.BatchNorm2d(c))

        self.initial = Residual(C_in, C_hid, 3, 1, 1, dropout_p=dropout_p,
                                norm=norm, groups=groups, padding_mode=padding_mode)

        self.branches = nn.ModuleList([
            Residual(C_hid, C_out, kernel_size=k, stride=1, padding=k//2,
                     dropout_p=dropout_p, norm=norm, groups=groups, padding_mode=padding_mode)
            for k in incep_ker
        ])

        self.merge = nn.Sequential(
            nn.Conv2d(len(incep_ker)*C_out, C_out, kernel_size=1, bias=False),
            Norm(C_out),
            nn.GELU(),                    # <- æ–°å¢žæ¿€æ´»
            # å¯é€‰ï¼šnn.Dropout2d(p=0.1)
        )

        # å…¨å±€æ®‹å·®ï¼ˆé€šé“å¯¹é½+æ ‡å®š+é—¨æŽ§ï¼‰
        self.skip = nn.Sequential(
            nn.Conv2d(C_in, C_out, kernel_size=1, bias=False),
            Norm(C_out)
        )
        self.skip_gate = nn.Parameter(torch.tensor(1.0))

    def forward(self, x, mask=None):
        x0 = self.skip(x)
        h  = self.initial(x)
        h  = torch.cat([b(h) for b in self.branches], dim=1)
        h  = self.merge(h)
        y  = h + self.skip_gate * x0

        # æŽ©è†œï¼ˆå¦‚æžœæœ‰ç¼ºæµ‹/æµ·é¢ç­‰ï¼‰â€”â€”å¯æ˜¾è‘—å‡å°‘èƒŒæ™¯â€œèŠ±â€
        if mask is not None:
            y = y.masked_fill(mask, float('nan'))
        return y

class Residual(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dropout_p=0.1):
        super(Residual, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu = nn.GELU()
        self.dropout = nn.Dropout2d(dropout_p)
        
        # If input and output channels don't match, add a 1x1 convolution to match the dimensions
        self.match_channels = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else None

    def forward(self, x):
        # Save the input for the residual connection
        residual = x

        # First convolution block
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        #x = self.dropout(x)

        # Second convolution block
        x = self.conv2(x)
        x = self.bn2(x)
        #x = self.dropout(x) 

        # If the input and output channels don't match, adjust the residual
        if self.match_channels:
            residual = self.match_channels(residual)

        # Add the residual connection
        x += residual
        x = self.relu(x)
        return x

# ç›®å‰æœ€ä¼˜
class TranslatorWithResidual(nn.Module):
    def __init__(self, C_in, C_hid, C_out, incep_ker=[3, 5, 7], groups=4, dropout_p=0.1):
        super(TranslatorWithResidual, self).__init__()

        # Initial convolution block with residual
        self.initial = Residual(C_in, C_hid, kernel_size=3, stride=1, padding=1, dropout_p=dropout_p)

        # Branches for multi-scale features (inception-style)
        self.branches = nn.ModuleList([
            Residual(C_hid, C_out, kernel_size=k, stride=1, padding=k//2, dropout_p=dropout_p)
            for k in incep_ker
        ])

        # Merge layers for final output
        self.merge = nn.Sequential(
            nn.Conv2d(len(incep_ker) * C_out, C_out, kernel_size=1),
            nn.BatchNorm2d(C_out),
            nn.Dropout2d(p=0.2)
        )

    def forward(self, x):
        residual = self.initial(x)  # ä¿å­˜åˆæ­¥ç‰¹å¾
        
        branch_outputs = [branch(residual) for branch in self.branches]
        x = torch.cat(branch_outputs, dim=1)
        x = self.merge(x)

        return x

def segmented_weighted_loss(x_recon, x_target):
    """
    x_recon, x_target: shape [B, C, H, W, T]
    """
    # å½’ä¸€åŒ–å¤„ç†ï¼ˆæ”¯æŒ 0-1 æˆ– 0-255 è¾“å…¥ï¼‰
    x_target_255 = x_target * 255 if x_target.max() <= 1 else x_target
    x_recon_255 = x_recon * 255 if x_recon.max() <= 1 else x_recon

    weights = torch.ones_like(x_target_255)

    # è‰²é˜¶åˆ†æ®µæƒé‡ï¼ˆå¯ä»¥è‡ªå®šä¹‰ï¼‰
    weights[(x_target_255 >= 16) & (x_target_255 < 181)] = 1.0
    weights[(x_target_255 >= 181) & (x_target_255 < 219)] = 5.0
    weights[(x_target_255 >= 219) & (x_target_255 <= 255)] = 10.0

    abs_diff = torch.abs(x_recon - x_target)

    # å¸§çº§å¹³å‡ï¼ˆå¯è§†ä¸º temporal attentionï¼‰
    frame_losses = (weights * abs_diff).flatten(1, -1).mean(dim=1)  # [B]
    loss = frame_losses.mean()
    return loss

class SSCVAE(nn.Module):
    def __init__(self,
                 in_channels_sate,# è¾“å…¥é€šé“æ•°ä¸º3ï¼šå«æ˜Ÿ
                 in_channels_radar,# é€šé“æ•°ä¸º1ï¼šé›·è¾¾å›¾åƒ
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,  # ç¼–ç å™¨çš„è¾“å‡ºé€šé“æ•°ï¼Œå®ƒå®šä¹‰äº†åœ¨ä¸‹é‡‡æ ·åŽçš„ç‰¹å¾å›¾çš„æ·±åº¦ã€‚è¿™ä¸ªå€¼å†³å®šäº†ä»Žè¾“å…¥åˆ°æ½œåœ¨ç©ºé—´çš„ç»´åº¦ã€‚é€šå¸¸æ¯” hid_channels_2 æ›´å¤§ï¼Œä¾‹å¦‚ 128 æˆ– 256ã€‚
                 down_samples,
                 num_groups,
                 num_atoms,# å­—å…¸çš„åŽŸå­ä¸ªæ•°ï¼Œä¸Žnum_dimsç›¸åŒ¹é…
                 num_dims, # æ¯ä¸ªåŽŸå­çš„ç»´åº¦
                 num_iters,# å†³å®šç¨€ç–ç¼–ç çš„æ”¶æ•›é€Ÿåº¦å’Œç²¾åº¦
                 device,
                 use_time_attention=False):  # æ·»åŠ å‚æ•°æŽ§åˆ¶æ˜¯å¦ä½¿ç”¨æ—¶é—´æ³¨æ„åŠ›
        super(SSCVAE, self).__init__()

        self._encoder_sate = Encoder(in_channels=in_channels_sate,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                down_samples=down_samples,
                                num_groups=num_groups)

        self._decoder_sate = Decoder(in_channels=in_channels_sate,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                up_samples=down_samples,
                                num_groups=num_groups)

        self._encoder_radar = Encoder(in_channels=in_channels_radar,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                down_samples=down_samples,
                                num_groups=num_groups)

        self._decoder_radar= Decoder(in_channels=in_channels_radar,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                up_samples=down_samples,
                                num_groups=num_groups)

        self._LISTA = AttentiveLISTA(num_atoms=num_atoms,
                                     num_dims=num_dims,
                                     num_iters=num_iters,
                                     device=device,
                                     use_time_attention=use_time_attention)

        self._mlp = TranslatorWithResidual(C_in=128, C_hid=196, C_out=128, incep_ker=[1,3,5])

    def generation(self, input_z):
        ex = self._LISTA.generation(input_z)  # [B, K, h, w] -> [B, D, h, w]
        x_generation = self._decoder_radar(ex)  # [B, D, h, w] -> [B, C, H, W]
        x_generation = torch.sigmoid(x_generation)
        return ex,x_generation
    
    def get_dict(self):
        return self._LISTA.get_dict()

    def forward(self, satellite, vil):
        # æ”¯æŒå•å¸§æˆ–å¤šå¸§è¾“å…¥ satellite: [B, T, C, H, W] æˆ– [B, C, H, W]
        # vil: [B, T, C, H, W] æˆ– [B, C, H, W]
        is_multi_frame = (satellite.dim() == 5)
        
        if is_multi_frame:
            satellite = satellite.permute(0, 4, 1, 2, 3).contiguous()  # [B, C, H, W, T] -> [B, T, C, H, W]
            vil = vil.permute(0, 4, 1, 2, 3).contiguous()
            
            B, T, C_sat, H, W = satellite.size()
            _, _, C_vil, _, _ = vil.size()
            
            # å±•å¹³æ—¶é—´ç»´åº¦è¿›è¡Œç¼–ç 
            satellite_flat = satellite.view(B * T, C_sat, H, W)
            vil_flat = vil.view(B * T, C_vil, H, W)
            
            ex = self._encoder_sate(satellite_flat)  # [B*T, D, h, w]
            ex_radar = self._encoder_radar(vil_flat)  # [B*T, D, h, w]
            
            # æ¢å¤æ—¶é—´ç»´åº¦åŽé€å…¥ LISTAï¼ˆLISTAå†…éƒ¨ä¼šæ ¹æ®use_time_attentionå†³å®šæ˜¯å¦ç”¨æ—¶é—´æ³¨æ„åŠ›ï¼‰
            _, D, h, w = ex.size()
            ex = ex.view(B, T, D, h, w)
            ex_radar = ex_radar.view(B, T, D, h, w)
        else:
            # å•å¸§è¾“å…¥ç›´æŽ¥ç¼–ç 
            ex = self._encoder_sate(satellite)  # [B, D, h, w]
            ex_radar = self._encoder_radar(vil)

        # LISTA å¤„ç†ï¼ˆå¤šå¸§æˆ–å•å¸§ï¼‰
        z, ex_recon, dictionary = self._LISTA(ex)  # è¾“å‡ºå¯èƒ½æ˜¯ [B, T, K, h, w] æˆ– [B, K, h, w]
        z_radar, ex_recon_radar, dictionary_radar = self._LISTA(ex_radar)

        # TranslatorWithResidual 2Dé€å¸§è½¬æ¢
        if is_multi_frame:
            # å±•å¹³æ—¶é—´ç»´åº¦é€å¸§è½¬æ¢
            z_flat = z.view(B * T, -1, h, w)  # [B*T, K, h, w]
            z_trans_flat = self._mlp(z_flat)  # [B*T, K, h, w]
            z_trans = z_trans_flat.view(B, T, -1, h, w)  # [B, T, K, h, w]
        else:
            z_trans = self._mlp(z)  # [B, K, h, w]

        # ç”Ÿæˆå’Œè§£ç 
        if is_multi_frame:
            # é€å¸§ç”Ÿæˆ
            ex_trans_list = []
            x_recon_trans_list = []
            for t in range(T):
                ex_t, x_t = self.generation(z_trans[:, t])  # [B, D, h, w], [B, C, H, W]
                ex_trans_list.append(ex_t)
                x_recon_trans_list.append(x_t)
            ex_trans = torch.stack(ex_trans_list, dim=1)  # [B, T, D, h, w]
            x_recon_trans = torch.stack(x_recon_trans_list, dim=1)  # [B, T, C, H, W]
        else:
            ex_trans, x_recon_trans = self.generation(z_trans)

        reconstruction_loss = segmented_weighted_loss(x_recon_trans, vil)

        z_diff_loss = F.mse_loss(z_trans, z_radar)
        latent_dist_loss = z_diff_loss

        latent_trans_loss = torch.sum((ex_trans - ex_radar).pow(2), dim=1).mean()

        return x_recon_trans, z, latent_dist_loss, latent_trans_loss, reconstruction_loss, dictionary

class SSCVAEDouble(nn.Module):
    def __init__(self,
                 in_channels_sate,# è¾“å…¥é€šé“æ•°ä¸º3ï¼šå«æ˜Ÿ
                 in_channels_radar,# é€šé“æ•°ä¸º1ï¼šé›·è¾¾å›¾åƒ
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,  # ç¼–ç å™¨çš„è¾“å‡ºé€šé“æ•°ï¼Œå®ƒå®šä¹‰äº†åœ¨ä¸‹é‡‡æ ·åŽçš„ç‰¹å¾å›¾çš„æ·±åº¦ã€‚è¿™ä¸ªå€¼å†³å®šäº†ä»Žè¾“å…¥åˆ°æ½œåœ¨ç©ºé—´çš„ç»´åº¦ã€‚é€šå¸¸æ¯” hid_channels_2 æ›´å¤§ï¼Œä¾‹å¦‚ 128 æˆ– 256ã€‚
                 down_samples,
                 num_groups,
                 num_atoms,# å­—å…¸çš„åŽŸå­ä¸ªæ•°ï¼Œä¸Žnum_dimsç›¸åŒ¹é…
                 num_dims, # æ¯ä¸ªåŽŸå­çš„ç»´åº¦
                 num_iters,# å†³å®šç¨€ç–ç¼–ç çš„æ”¶æ•›é€Ÿåº¦å’Œç²¾åº¦
                 device,
                 use_time_attention=False):  # æ·»åŠ å‚æ•°æŽ§åˆ¶æ˜¯å¦ä½¿ç”¨æ—¶é—´æ³¨æ„åŠ›
        super(SSCVAEDouble, self).__init__()

        self._encoder_sate = Encoder(in_channels=in_channels_sate,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                down_samples=down_samples,
                                num_groups=num_groups)

        self._decoder_sate = Decoder(in_channels=in_channels_sate,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                up_samples=down_samples,
                                num_groups=num_groups)# è§£ç ä¸ºä¸‰é€šé“

        self._encoder_radar = Encoder(in_channels=in_channels_radar,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                down_samples=down_samples,
                                num_groups=num_groups)

        self._decoder_radar= Decoder(in_channels=in_channels_radar,
                                hid_channels_1=hid_channels_1,
                                hid_channels_2=hid_channels_2,
                                out_channels=out_channels,
                                up_samples=down_samples,
                                num_groups=num_groups)# è§£ç ä¸ºä¸‰é€šé“

        self._LISTA = AttentiveLISTA(num_atoms=num_atoms,
                                     num_dims=num_dims,
                                     num_iters=num_iters,
                                     device=device,
                                     use_time_attention=use_time_attention)

    def generation(self, input_z, is_sate=True):
        if is_sate:
            ex = self._LISTA.generation(input_z)  # [B, K, h, w] -> [B, D, h, w]
            x_generation = self._decoder_sate(ex)  # [B, D, h, w] -> [B, C, H, W]
        else:
            ex = self._LISTA.generation(input_z)
            x_generation = self._decoder_radar(ex)
        
        x_generation = torch.sigmoid(x_generation)
        return x_generation

    
    def get_dict(self):
        return self._LISTA.get_dict()

    def forward(self, satellite, vil):
        # æ”¯æŒå•å¸§æˆ–å¤šå¸§è¾“å…¥
        is_multi_frame = (satellite.dim() == 5)
        
        if is_multi_frame:
            satellite = satellite.permute(0, 4, 1, 2, 3).contiguous()  # [B, C, H, W, T] -> [B, T, C, H, W]
            vil = vil.permute(0, 4, 1, 2, 3).contiguous()
            
            B, T, C_sat, H, W = satellite.size()
            _, _, C_vil, _, _ = vil.size()
            
            # å±•å¹³æ—¶é—´ç»´åº¦è¿›è¡Œç¼–ç 
            satellite_flat = satellite.view(B * T, C_sat, H, W)
            vil_flat = vil.view(B * T, C_vil, H, W)
            
            ex_sate = self._encoder_sate(satellite_flat)  # [B*T, D, h, w]
            ex_radar = self._encoder_radar(vil_flat)  # [B*T, D, h, w]
            
            # æ¢å¤æ—¶é—´ç»´åº¦
            _, D, h, w = ex_sate.size()
            ex_sate = ex_sate.view(B, T, D, h, w)
            ex_radar = ex_radar.view(B, T, D, h, w)
        else:
            # å•å¸§è¾“å…¥
            ex_sate = self._encoder_sate(satellite)  # [B, D, h, w]
            ex_radar = self._encoder_radar(vil)

        # LISTA å¤„ç†
        z_sate, ex_recon_sate, dictionary = self._LISTA(ex_sate)
        z_radar, ex_recon_radar, _ = self._LISTA(ex_radar)
        
        # è§£ç 
        if is_multi_frame:
            # å±•å¹³è§£ç 
            ex_recon_sate_flat = ex_recon_sate.view(B * T, D, h, w)
            ex_recon_radar_flat = ex_recon_radar.view(B * T, D, h, w)
            
            x_recon_sate_flat = self._decoder_sate(ex_recon_sate_flat)
            x_recon_radar_flat = self._decoder_radar(ex_recon_radar_flat)
            
            # æ¢å¤æ—¶é—´ç»´åº¦
            x_recon_sate = torch.sigmoid(x_recon_sate_flat.view(B, T, C_sat, H, W))
            x_recon_radar = torch.sigmoid(x_recon_radar_flat.view(B, T, C_vil, H, W))
        else:
            x_recon_sate = torch.sigmoid(self._decoder_sate(ex_recon_sate))
            x_recon_radar = torch.sigmoid(self._decoder_radar(ex_recon_radar))

        # è®¡ç®—æŸå¤±
        latent_loss_sate = torch.sum((ex_recon_sate - ex_sate).pow(2), dim=1).mean()
        latent_loss_radar = torch.sum((ex_recon_radar - ex_radar).pow(2), dim=1).mean()
        total_latent_loss = latent_loss_sate + latent_loss_radar

        return x_recon_sate, x_recon_radar, z_sate, z_radar, total_latent_loss, dictionary


# ============================================================================
# ðŸŽ¬ 3D æ—¶ç©ºå·ç§¯æ¨¡å— (ç”¨äºŽçœŸæ­£çš„å¤šå¸§æ—¶åºå»ºæ¨¡)
# ============================================================================

# 3D æ®‹å·®å—
class ResidualBlock3D(nn.Module):
    def __init__(self, in_channels, hid_channels):
        super(ResidualBlock3D, self).__init__()
        
        self._block = nn.Sequential(
            nn.ReLU(inplace=True),
            nn.Conv3d(in_channels=in_channels,
                      out_channels=hid_channels,
                      kernel_size=3, stride=1, padding=1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv3d(in_channels=hid_channels,
                      out_channels=in_channels,
                      kernel_size=1, stride=1, bias=False)
        )
    
    def forward(self, x):
        return x + self._block(x)


# 3D ä¸‹é‡‡æ ·ï¼ˆåªåœ¨ç©ºé—´ç»´åº¦ä¸‹é‡‡æ ·ï¼Œæ—¶é—´ç»´åº¦ä¿æŒï¼‰
class DownSampleBlock3D(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DownSampleBlock3D, self).__init__()

        self._block = nn.Sequential(
            nn.Conv3d(in_channels=in_channels,
                      out_channels=out_channels,
                      kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))  # åªåœ¨ H,W ä¸‹é‡‡æ ·
        )
    
    def forward(self, x):
        return self._block(x)


# 3D ä¸Šé‡‡æ ·ï¼ˆåªåœ¨ç©ºé—´ç»´åº¦ä¸Šé‡‡æ ·ï¼Œæ—¶é—´ç»´åº¦ä¿æŒï¼‰
class UpSampleBlock3D(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(UpSampleBlock3D, self).__init__()

        self._block = nn.Sequential(
            nn.ConvTranspose3d(in_channels=in_channels,
                               out_channels=out_channels,
                               kernel_size=(1, 2, 2), stride=(1, 2, 2)),  # åªåœ¨ H,W ä¸Šé‡‡æ ·
            nn.Conv3d(in_channels=out_channels,
                      out_channels=out_channels,
                      kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        return self._block(x)


# 3D éžå±€éƒ¨æ³¨æ„åŠ›å—
class NonLocalBlock3D(nn.Module):
    def __init__(self, in_channels, hid_channels):
        super(NonLocalBlock3D, self).__init__()

        self.hid_channels = hid_channels
        self._conv_theta = nn.Conv3d(in_channels=in_channels,
                                     out_channels=hid_channels,
                                     kernel_size=1, stride=1, padding=0, bias=False)
        self._conv_phi = nn.Conv3d(in_channels=in_channels,
                                   out_channels=hid_channels,
                                   kernel_size=1, stride=1, padding=0, bias=False)
        self._conv_g = nn.Conv3d(in_channels=in_channels,
                                 out_channels=hid_channels,
                                 kernel_size=1, stride=1, padding=0, bias=False)
        self._soft_max = nn.Softmax(dim=1)
        self._conv_mask = nn.Conv3d(in_channels=hid_channels,
                                    out_channels=in_channels,
                                    kernel_size=1, stride=1, padding=0, bias=False)

    def forward(self, x):
        b, c, t, h, w = x.size()

        # [B, C, T, H, W] -> [B, C', THW] -> [B, THW, C']
        theta = self._conv_theta(x).view(b, self.hid_channels, -1).permute(0, 2, 1).contiguous()
        # [B, C, T, H, W] -> [B, C', THW]
        phi = self._conv_phi(x).view(b, self.hid_channels, -1)
        # [B, C, T, H, W] -> [B, C', THW] -> [B, THW, C']
        g = self._conv_g(x).view(b, self.hid_channels, -1).permute(0, 2, 1).contiguous()
        # [B, THW, C'] * [B, C', THW] = [B, THW, THW]
        mul_theta_phi = self._soft_max(torch.matmul(theta, phi))
        # [B, THW, THW] * [B, THW, C'] = [B, THW, C']
        mul_theta_phi_g = torch.matmul(mul_theta_phi, g)
        # [B, THW, C'] -> [B, C', THW] -> [B, C', T, H, W]
        mul_theta_phi_g = mul_theta_phi_g.permute(0, 2, 1).contiguous().view(b, self.hid_channels, t, h, w)
        # [B, C', T, H, W] -> [B, C, T, H, W]
        mask = self._conv_mask(mul_theta_phi_g)

        return x + mask


# 3D é€šé“æ³¨æ„åŠ›
class ChannelAttention3D(nn.Module):
    def __init__(self, in_channels, reduction):
        super(ChannelAttention3D, self).__init__()
        self._avg_pool = nn.AdaptiveAvgPool3d(1)  # å…¨å±€å¹³å‡æ± åŒ–
        self._max_pool = nn.AdaptiveMaxPool3d(1)  # æœ€å¤§æ± åŒ–
        self._fc = nn.Sequential(
            nn.Linear(in_channels, in_channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(in_channels // reduction, in_channels, bias=False),
        )
        self._sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        b, c, _, _, _ = x.size()
        avgOut = self._fc(self._avg_pool(x).view(b, c))
        maxOut = self._fc(self._max_pool(x).view(b, c))
        y = self._sigmoid(avgOut + maxOut).view(b, c, 1, 1, 1)
        return x * y.expand_as(x)


# 3D ç©ºé—´æ³¨æ„åŠ›
class SpatialAttention3D(nn.Module):
    def __init__(self, kernel_size):
        super(SpatialAttention3D, self).__init__()
        self._conv = nn.Conv3d(in_channels=2,
                               out_channels=1,
                               kernel_size=kernel_size,
                               stride=1,
                               padding=(kernel_size - 1) // 2,
                               bias=False)
        self._sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avgOut = torch.mean(x, dim=1, keepdim=True)
        maxOut, _ = torch.max(x, dim=1, keepdim=True)
        y = torch.cat([avgOut, maxOut], dim=1)
        y = self._sigmoid(self._conv(y))
        return x * y.expand_as(x)


# 3D CBAM
class CBAM3D(nn.Module):
    def __init__(self, in_channels, reduction, kernel_size):
        super(CBAM3D, self).__init__()
        self.ChannelAtt = ChannelAttention3D(in_channels, reduction)
        self.SpatialAtt = SpatialAttention3D(kernel_size)
    
    def forward(self, x):
        x = self.ChannelAtt(x)
        x = self.SpatialAtt(x)
        return x


# 3D ç¼–ç å™¨
class Encoder3D(nn.Module):
    def __init__(self,
                 in_channels,
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,
                 down_samples,
                 num_groups):
        super(Encoder3D, self).__init__()

        # [B, C, T, H, W] -> [B, C', T, H, W]
        self._conv_1 = nn.Conv3d(in_channels=in_channels,
                                 out_channels=hid_channels_1,
                                 kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        
        # [B, C', T, H, W] -> [B, C'', T, h, w]
        self._down_samples = nn.ModuleList()
        for i in range(down_samples):
            cur_in_channels = hid_channels_1 if i == 0 else hid_channels_2
            self._down_samples.append(
                ResidualBlock3D(in_channels=cur_in_channels,
                                hid_channels=cur_in_channels // 2)
            )
            self._down_samples.append(
                DownSampleBlock3D(in_channels=cur_in_channels,
                                  out_channels=hid_channels_2)
            )

        # [B, C'', T, h, w] -> [B, C'', T, h, w]
        self._res_1 = ResidualBlock3D(in_channels=hid_channels_2,
                                      hid_channels=hid_channels_2 // 2)
        self._non_local = NonLocalBlock3D(in_channels=hid_channels_2,
                                          hid_channels=hid_channels_2 // 2)
        self._res_2 = ResidualBlock3D(in_channels=hid_channels_2,
                                      hid_channels=hid_channels_2 // 2)
        
        self._group_norm = nn.GroupNorm(num_groups=num_groups,
                                        num_channels=hid_channels_2)
        self._swish = Swish()

        # [B, C'', T, h, w] -> [B, D, T, h, w]
        self._conv_2 = nn.Conv3d(in_channels=hid_channels_2,
                                 out_channels=out_channels,
                                 kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))

    def forward(self, x):  # [B, C, T, H, W]
        x = self._conv_1(x)

        for layer in self._down_samples:
            x = layer(x)

        x = self._res_1(x)
        x = self._non_local(x)
        x = self._res_2(x)

        # GroupNorm éœ€è¦ç‰¹æ®Šå¤„ç†ï¼š[B, C, T, H, W] -> [B, C, T*H, W]
        b, c, t, h, w = x.size()
        x = x.view(b, c, t*h, w)
        x = self._group_norm(x)
        x = x.view(b, c, t, h, w)
        
        x = self._swish(x)
        x = self._conv_2(x)

        return x  # [B, D, T, h, w]


# 3D è§£ç å™¨
class Decoder3D(nn.Module):
    def __init__(self,
                 in_channels,
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,
                 up_samples,
                 num_groups):
        super(Decoder3D, self).__init__()

        # [B, D, T, h, w] -> [B, C'', T, h, w]
        self._conv_1 = nn.Conv3d(in_channels=out_channels,
                                 out_channels=hid_channels_2,
                                 kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))

        # [B, C'', T, h, w] -> [B, C'', T, h, w]
        self._res_1 = ResidualBlock3D(in_channels=hid_channels_2,
                                      hid_channels=hid_channels_2 // 2)
        self._non_local = NonLocalBlock3D(in_channels=hid_channels_2,
                                          hid_channels=hid_channels_2 // 2)
        self._res_2 = ResidualBlock3D(in_channels=hid_channels_2,
                                      hid_channels=hid_channels_2 // 2)
        
        # [B, C'', T, h, w] -> [B, C', T, H, W]
        self._up_samples = nn.ModuleList()
        for i in range(up_samples):
            cur_in_channels = hid_channels_2 if i == 0 else hid_channels_1
            self._up_samples.append(
                ResidualBlock3D(in_channels=cur_in_channels,
                                hid_channels=cur_in_channels // 2)
            )
            self._up_samples.append(
                UpSampleBlock3D(in_channels=cur_in_channels,
                                out_channels=hid_channels_1)
            )
        
        # [B, C', T, H, W] -> [B, C', T, H, W]
        self._group_norm = nn.GroupNorm(num_groups=num_groups,
                                        num_channels=hid_channels_1)
        self._swish = Swish()

        # [B, C', T, H, W] -> [B, C, T, H, W]
        self._conv_2 = nn.Conv3d(in_channels=hid_channels_1,
                                 out_channels=in_channels,
                                 kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        
    def forward(self, x):  # [B, D, T, h, w]
        x = self._conv_1(x)
        
        x = self._res_1(x)
        x = self._non_local(x)
        x = self._res_2(x)

        for layer in self._up_samples:
            x = layer(x)

        # GroupNorm éœ€è¦ç‰¹æ®Šå¤„ç†
        b, c, t, h, w = x.size()
        x = x.view(b, c, t*h, w)
        x = self._group_norm(x)
        x = x.view(b, c, t, h, w)
        
        x = self._swish(x)
        x = self._conv_2(x)

        return x  # [B, C, T, H, W]


# 3D AttentiveLISTA (ä¿æŒæ—¶é—´ç»´åº¦çš„ç¨€ç–ç¼–ç )
class AttentiveLISTA3D(nn.Module):
    def __init__(self,
                 num_atoms,
                 num_dims,
                 num_iters,
                 device):
        super(AttentiveLISTA3D, self).__init__()

        self._num_atoms = num_atoms
        self._num_dims = num_dims
        self._device = device

        self._Dict = nn.Parameter(self.initialize_dct_weights())  # [D, K]
        self._L = nn.Parameter((torch.norm(self._Dict, p=2)) ** 2)  # scalar
        
        # 3D å·ç§¯å¤„ç†æ—¶ç©ºç‰¹å¾
        self._conv = nn.Conv3d(in_channels=num_dims,
                               out_channels=num_atoms,
                               kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        self._res1 = ResidualBlock3D(in_channels=num_atoms,
                                     hid_channels=num_atoms//2)
        self._res2 = ResidualBlock3D(in_channels=num_atoms,
                                     hid_channels=num_atoms//2)
        self._cbam = CBAM3D(in_channels=num_atoms,
                            reduction=16,
                            kernel_size=3)

        self._Zero = torch.zeros(num_atoms).to(device)  # [K]
        self._Identity = torch.eye(num_atoms).to(device)  # [K, K]

        self._num_iters = num_iters
    
    def initialize_dct_weights(self):
        n = math.ceil(math.sqrt(self._num_dims))
        m = math.ceil(math.sqrt(self._num_atoms))
        weights = init_dct(n, m)[:, :self._num_atoms]  # [D, K]
        return weights
    
    def get_dict(self):
        return self._Dict
    
    def set_dict(self, dictionary):
        self._Dict = nn.Parameter(dictionary)
        print("Dictionary initialized with pretrained values.")

    def soft_thresh(self, x, theta):
        return torch.sign(x) * torch.max(torch.abs(x) - theta, self._Zero)

    def generation(self, input_z):  # [B, K, T, h, w]
        # è½¬æ¢ç»´åº¦ç”¨äºŽçŸ©é˜µä¹˜æ³•
        b, k, t, h, w = input_z.size()
        input_z = input_z.permute(0, 2, 3, 4, 1).contiguous()  # [B, T, h, w, K]
        input_z = input_z.view(b * t * h * w, k)  # [B*T*h*w, K]
        
        x_recon = torch.matmul(input_z, self._Dict.t())  # [B*T*h*w, K] * [K, D] -> [B*T*h*w, D]
        x_recon = x_recon.view(b, t, h, w, self._num_dims).permute(0, 4, 1, 2, 3).contiguous()  # [B, D, T, h, w]
        return x_recon

    def forward(self, x):  # [B, D, T, H, W]
        B, D, T, H, W = x.size()
        
        # 3D å·ç§¯æå–æ—¶ç©ºç‰¹å¾
        l = self._conv(x)  # [B, D, T, H, W] -> [B, K, T, H, W]
        l = self._res1(l)
        l = self._res2(l)
        l = self._cbam(l) / self._L

        # ç¨€ç–ç¼–ç ï¼ˆåœ¨æ¯ä¸ªæ—¶ç©ºç‚¹ç‹¬ç«‹è¿›è¡Œï¼‰
        b, k, t, h, w = l.size()
        l = l.permute(0, 2, 3, 4, 1).contiguous()  # [B, K, T, H, W] -> [B, T, H, W, K]
        x = x.permute(0, 2, 3, 4, 1).contiguous()  # [B, D, T, H, W] -> [B, T, H, W, D]
        
        # å±•å¹³ç”¨äºŽçŸ©é˜µä¹˜æ³•
        l = l.view(b * t * h * w, k)  # [B*T*H*W, K]
        x = x.view(b * t * h * w, D)  # [B*T*H*W, D]
        
        S = self._Identity - (1 / self._L) * self._Dict.t().mm(self._Dict)  # [K, K]
        S = S.t()  # [K, K]

        y = torch.matmul(x, self._Dict)  # [B*T*H*W, D] * [D, K] -> [B*T*H*W, K]

        z = self.soft_thresh(y, l)  # [B*T*H*W, K]
        for iter_t in range(self._num_iters):
            z = self.soft_thresh(torch.matmul(z, S) + (1 / self._L) * y, l)

        x_recon = torch.matmul(z, self._Dict.t())  # [B*T*H*W, K] * [K, D] -> [B*T*H*W, D]

        # æ¢å¤ç»´åº¦
        z = z.view(b, t, h, w, k).permute(0, 4, 1, 2, 3).contiguous()  # [B, K, T, h, w]
        x_recon = x_recon.view(b, t, h, w, D).permute(0, 4, 1, 2, 3).contiguous()  # [B, D, T, h, w]

        return z, x_recon, self._Dict


# 3D Residual å—ï¼ˆç”¨äºŽ TranslatorWithResidual3Dï¼‰
class Residual3D(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dropout_p=0.1):
        super(Residual3D, self).__init__()
        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)
        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size, stride, padding)
        self.bn1 = nn.BatchNorm3d(out_channels)
        self.bn2 = nn.BatchNorm3d(out_channels)
        self.relu = nn.GELU()
        self.dropout = nn.Dropout3d(dropout_p)
        
        # If input and output channels don't match, add a 1x1 convolution
        self.match_channels = nn.Conv3d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else None

    def forward(self, x):
        residual = x

        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)

        x = self.conv2(x)
        x = self.bn2(x)

        if self.match_channels:
            residual = self.match_channels(residual)

        x += residual
        x = self.relu(x)
        return x


# 3D TranslatorWithResidual
class TranslatorWithResidual3D(nn.Module):
    def __init__(self, C_in, C_hid, C_out, incep_ker=[3, 5, 7], dropout_p=0.1):
        super(TranslatorWithResidual3D, self).__init__()

        # Initial convolution block with residual
        self.initial = Residual3D(C_in, C_hid, kernel_size=3, stride=1, padding=1, dropout_p=dropout_p)

        # Branches for multi-scale features (inception-style)
        self.branches = nn.ModuleList([
            Residual3D(C_hid, C_out, kernel_size=k, stride=1, padding=k//2, dropout_p=dropout_p)
            for k in incep_ker
        ])

        # Merge layers for final output
        self.merge = nn.Sequential(
            nn.Conv3d(len(incep_ker) * C_out, C_out, kernel_size=1),
            nn.BatchNorm3d(C_out),
            nn.Dropout3d(p=0.2)
        )

    def forward(self, x):  # [B, C_in, T, h, w]
        residual = self.initial(x)  # [B, C_hid, T, h, w]
        
        branch_outputs = [branch(residual) for branch in self.branches]
        x = torch.cat(branch_outputs, dim=1)  # [B, len(incep_ker)*C_out, T, h, w]
        x = self.merge(x)  # [B, C_out, T, h, w]

        return x


# ============================================================================
# ðŸŽ¬ 3D SSCVAE (çœŸæ­£çš„å¤šå¸§æ—¶åºæ¨¡åž‹)
# ============================================================================

class SSCVAE3D(nn.Module):
    def __init__(self,
                 in_channels_sate,  # å«æ˜Ÿå›¾åƒé€šé“æ•° (3)
                 in_channels_radar,  # é›·è¾¾å›¾åƒé€šé“æ•° (1)
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,
                 down_samples,
                 num_groups,
                 num_atoms,
                 num_dims,
                 num_iters,
                 device):
        super(SSCVAE3D, self).__init__()

        self._encoder_sate = Encoder3D(in_channels=in_channels_sate,
                                       hid_channels_1=hid_channels_1,
                                       hid_channels_2=hid_channels_2,
                                       out_channels=out_channels,
                                       down_samples=down_samples,
                                       num_groups=num_groups)

        self._decoder_sate = Decoder3D(in_channels=in_channels_sate,
                                       hid_channels_1=hid_channels_1,
                                       hid_channels_2=hid_channels_2,
                                       out_channels=out_channels,
                                       up_samples=down_samples,
                                       num_groups=num_groups)

        self._encoder_radar = Encoder3D(in_channels=in_channels_radar,
                                        hid_channels_1=hid_channels_1,
                                        hid_channels_2=hid_channels_2,
                                        out_channels=out_channels,
                                        down_samples=down_samples,
                                        num_groups=num_groups)

        self._decoder_radar = Decoder3D(in_channels=in_channels_radar,
                                        hid_channels_1=hid_channels_1,
                                        hid_channels_2=hid_channels_2,
                                        out_channels=out_channels,
                                        up_samples=down_samples,
                                        num_groups=num_groups)

        self._LISTA = AttentiveLISTA3D(num_atoms=num_atoms,
                                       num_dims=num_dims,
                                       num_iters=num_iters,
                                       device=device)

        self._mlp = TranslatorWithResidual3D(C_in=128, C_hid=196, C_out=128, incep_ker=[1, 3, 5])

    def generation(self, input_z):
        ex = self._LISTA.generation(input_z)  # [B, K, T, h, w] -> [B, D, T, h, w]
        x_generation = self._decoder_radar(ex)  # [B, D, T, h, w] -> [B, C, T, H, W]
        x_generation = torch.sigmoid(x_generation)
        return ex, x_generation
    
    def get_dict(self):
        return self._LISTA.get_dict()

    def forward(self, satellite, vil):
        """
        Args:
            satellite: [B, C, H, W, T] æˆ– [B, C, T, H, W]
            vil: [B, C, H, W, T] æˆ– [B, C, T, H, W]
        Returns:
            x_recon_trans: [B, C, T, H, W]
            z: [B, K, T, h, w]
            ...
        """
        # ç»Ÿä¸€è¾“å…¥æ ¼å¼ä¸º [B, C, T, H, W]
        if satellite.dim() == 5:
            # åˆ¤æ–­æ˜¯ [B, C, H, W, T] è¿˜æ˜¯ [B, C, T, H, W]
            if satellite.size(2) < satellite.size(4):  # H < Tï¼Œè¯´æ˜Žæ˜¯ [B, C, H, W, T]
                satellite = satellite.permute(0, 1, 4, 2, 3).contiguous()  # -> [B, C, T, H, W]
                vil = vil.permute(0, 1, 4, 2, 3).contiguous()
        
        # 3D ç¼–ç ï¼ˆæ—¶ç©ºè”åˆï¼‰
        ex = self._encoder_sate(satellite)  # [B, C, T, H, W] -> [B, D, T, h, w]
        ex_radar = self._encoder_radar(vil)  # [B, C, T, H, W] -> [B, D, T, h, w]

        # 3D ç¨€ç–ç¼–ç 
        z, ex_recon, dictionary = self._LISTA(ex)  # [B, D, T, h, w] -> [B, K, T, h, w]
        z_radar, ex_recon_radar, dictionary_radar = self._LISTA(ex_radar)

        # 3D è½¬æ¢
        z_trans = self._mlp(z)  # [B, K, T, h, w] -> [B, K, T, h, w]

        # 3D è§£ç 
        ex_trans, x_recon_trans = self.generation(z_trans)  # [B, K, T, h, w] -> [B, C, T, H, W]

        # è®¡ç®—æŸå¤±
        reconstruction_loss = segmented_weighted_loss(x_recon_trans, vil)
        z_diff_loss = F.mse_loss(z_trans, z_radar)
        latent_dist_loss = z_diff_loss
        latent_trans_loss = torch.sum((ex_trans - ex_radar).pow(2), dim=1).mean()

        return x_recon_trans, z, latent_dist_loss, latent_trans_loss, reconstruction_loss, dictionary


# 3D SSCVAEDouble (åŒè§£ç å™¨ç‰ˆæœ¬)
class SSCVAEDouble3D(nn.Module):
    def __init__(self,
                 in_channels_sate,
                 in_channels_radar,
                 hid_channels_1,
                 hid_channels_2,
                 out_channels,
                 down_samples,
                 num_groups,
                 num_atoms,
                 num_dims,
                 num_iters,
                 device):
        super(SSCVAEDouble3D, self).__init__()

        self._encoder_sate = Encoder3D(in_channels=in_channels_sate,
                                       hid_channels_1=hid_channels_1,
                                       hid_channels_2=hid_channels_2,
                                       out_channels=out_channels,
                                       down_samples=down_samples,
                                       num_groups=num_groups)

        self._decoder_sate = Decoder3D(in_channels=in_channels_sate,
                                       hid_channels_1=hid_channels_1,
                                       hid_channels_2=hid_channels_2,
                                       out_channels=out_channels,
                                       up_samples=down_samples,
                                       num_groups=num_groups)

        self._encoder_radar = Encoder3D(in_channels=in_channels_radar,
                                        hid_channels_1=hid_channels_1,
                                        hid_channels_2=hid_channels_2,
                                        out_channels=out_channels,
                                        down_samples=down_samples,
                                        num_groups=num_groups)

        self._decoder_radar = Decoder3D(in_channels=in_channels_radar,
                                        hid_channels_1=hid_channels_1,
                                        hid_channels_2=hid_channels_2,
                                        out_channels=out_channels,
                                        up_samples=down_samples,
                                        num_groups=num_groups)

        self._LISTA = AttentiveLISTA3D(num_atoms=num_atoms,
                                       num_dims=num_dims,
                                       num_iters=num_iters,
                                       device=device)

    def generation(self, input_z, is_sate=True):
        if is_sate:
            ex = self._LISTA.generation(input_z)
            x_generation = self._decoder_sate(ex)
        else:
            ex = self._LISTA.generation(input_z)
            x_generation = self._decoder_radar(ex)
        
        x_generation = torch.sigmoid(x_generation)
        return x_generation
    
    def get_dict(self):
        return self._LISTA.get_dict()

    def forward(self, satellite, vil):
        """
        Args:
            satellite: [B, C, H, W, T] æˆ– [B, C, T, H, W]
            vil: [B, C, H, W, T] æˆ– [B, C, T, H, W]
        Returns:
            x_recon_sate: [B, C, T, H, W]
            x_recon_radar: [B, C, T, H, W]
            z_sate: [B, K, T, h, w]
            z_radar: [B, K, T, h, w]
            total_latent_loss: scalar
            dictionary: [D, K]
        """
        # ç»Ÿä¸€è¾“å…¥æ ¼å¼ä¸º [B, C, T, H, W]
        if satellite.dim() == 5:
            if satellite.size(2) < satellite.size(4):  # H < Tï¼Œè¯´æ˜Žæ˜¯ [B, C, H, W, T]
                satellite = satellite.permute(0, 1, 4, 2, 3).contiguous()
                vil = vil.permute(0, 1, 4, 2, 3).contiguous()
        
        # 3D ç¼–ç 
        ex_sate = self._encoder_sate(satellite)  # [B, C, T, H, W] -> [B, D, T, h, w]
        ex_radar = self._encoder_radar(vil)

        # 3D ç¨€ç–ç¼–ç 
        z_sate, ex_recon_sate, dictionary = self._LISTA(ex_sate)  # [B, D, T, h, w] -> [B, K, T, h, w]
        z_radar, ex_recon_radar, _ = self._LISTA(ex_radar)
        
        # 3D è§£ç 
        x_recon_sate = torch.sigmoid(self._decoder_sate(ex_recon_sate))  # [B, K, T, h, w] -> [B, C, T, H, W]
        x_recon_radar = torch.sigmoid(self._decoder_radar(ex_recon_radar))

        # è®¡ç®—æŸå¤±
        latent_loss_sate = torch.sum((ex_recon_sate - ex_sate).pow(2), dim=1).mean()
        latent_loss_radar = torch.sum((ex_recon_radar - ex_radar).pow(2), dim=1).mean()
        total_latent_loss = latent_loss_sate + latent_loss_radar

        return x_recon_sate, x_recon_radar, z_sate, z_radar, total_latent_loss, dictionary
