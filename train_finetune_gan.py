"""
SSCVAE å…¨æ¨¡å‹å¾®è°ƒ + GAN Loss
æ•´åˆåˆ¤åˆ«å™¨æå‡é‡å»ºå›¾åƒçœŸå®æ„Ÿ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms

import os
import argparse
import json
from types import SimpleNamespace
import csv
from tqdm import tqdm

# é…ç½® cuDNN
torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False

from utils.utils import get_recon_loss, hoyer_metric
from models import SSCVAE
from discriminator import PatchGANDiscriminator, GANLoss
from utils.visualization import plot_dict
from data import SevirTimeTransDataset
import numpy as np


class EarlyStopping:
    def __init__(self, patience=10, min_delta=0, verbose=False, path='checkpoint.pth'):
        self.patience = patience
        self.min_delta = min_delta
        self.verbose = verbose
        self.counter = 0
        self.best_loss = np.inf
        self.early_stop = False
        self.path = path

    def __call__(self, val_loss, model):
        if self.best_loss - val_loss > self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            if self.verbose:
                print(f"Validation loss decreased ({self.best_loss} -> {val_loss}). Saving model...")
            torch.save(model.state_dict(), self.path)
        else:
            self.counter += 1
            if self.verbose:
                print(f"Validation loss did not improve for {self.counter} epochs.")
        if self.counter >= self.patience:
            self.early_stop = True


def get_lrs(optimizer):
    return [group['lr'] for group in optimizer.param_groups]


def get_weights(epoch):
    """åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡"""
    if epoch < 30:
        lambda_gan = 0.01    # ä¿æŒä¸€å®šçš„å¯¹æŠ—å¼ºåº¦
        lambda_trans = 0.2
    elif epoch < 60:
        lambda_gan = 0.03    # é€æ¸å¢åŠ 
        lambda_trans = 0.5
    else:
        lambda_gan = 0.05    # æœ€ç»ˆç¨³å®š
        lambda_trans = 0.7
    
    return dict(
        recon=1.0,
        trans=lambda_trans,
        gan=lambda_gan,
        sparse=1.0
    )


def train(data_args, model_args, train_args, test_args):
    model_fold_path = os.path.join(train_args.save_path, 'models')
    image_fold_path = os.path.join(train_args.save_path, 'images')
    dict_fold_path = os.path.join(train_args.save_path, 'dicts')
    os.makedirs(model_fold_path, exist_ok=True)
    os.makedirs(image_fold_path, exist_ok=True)
    os.makedirs(dict_fold_path, exist_ok=True)

    data_transform = {"train": transforms.Compose([]), "val": transforms.Compose([])}

    train_dataset = SevirTimeTransDataset(root_dir=data_args.root_dir, mode="train", transform=data_transform["train"])
    val_dataset = SevirTimeTransDataset(root_dir=data_args.root_dir, mode="val", transform=data_transform["val"])
    train_loader = DataLoader(train_dataset, batch_size=data_args.batch_size, shuffle=True, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)

    train_image_num = len(train_dataset)
    val_image_num = len(val_dataset)

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    
    # ============ æ¨¡å‹åˆå§‹åŒ– ============
    print("ğŸ“¦ åˆå§‹åŒ–ç”Ÿæˆå™¨ (SSCVAE)...")
    model = SSCVAE(**vars(model_args), device=device, use_time_attention=True).to(device)
    
    # åŠ è½½æœ€ä½³é¢„è®­ç»ƒæƒé‡
    pretrained_paths = [
        "/root/autodl-tmp/results/sscvae_recon_sevir_gan/models/best_model.pt"         # åŸºç¡€é¢„è®­ç»ƒ
    ]
    
    loaded = False
    for path in pretrained_paths:
        if os.path.exists(path):
            print(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæƒé‡: {path}")
            model.load_state_dict(torch.load(path, map_location=device), strict=False)
            print("âœ… é¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸï¼")
            loaded = True
            break
    
    if not loaded:
        print("âš ï¸  æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œå°†ä»å¤´è®­ç»ƒï¼ˆä¸æ¨èï¼‰")
    
    # ============ åˆ¤åˆ«å™¨åˆå§‹åŒ– ============
    print("\nğŸ­ åˆå§‹åŒ–åˆ¤åˆ«å™¨ (PatchGAN)...")
    discriminator = PatchGANDiscriminator(
        in_channels=1,  # VIL å•é€šé“
        ndf=64,
        n_layers=3
    ).to(device)
    
    print(f"   ç”Ÿæˆå™¨å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   åˆ¤åˆ«å™¨å‚æ•°: {sum(p.numel() for p in discriminator.parameters()):,}")
    
    # ============ ä¼˜åŒ–å™¨è®¾ç½® ============
    # ç”Ÿæˆå™¨ï¼šåˆ†å±‚å­¦ä¹ ç‡
    optimizer_G = torch.optim.AdamW([
        {'params': model._encoder_sate.parameters(), 'lr': 5e-6},
        {'params': model._encoder_radar.parameters(), 'lr': 5e-6},
        {'params': model._LISTA.parameters(), 'lr': 1e-5},
        {'params': model._decoder_radar.parameters(), 'lr': 3e-5},
        {'params': model._mlp.parameters(), 'lr': 5e-5},
    ], weight_decay=1e-5)
    
    # åˆ¤åˆ«å™¨ï¼šç‹¬ç«‹ä¼˜åŒ–å™¨
    optimizer_D = torch.optim.AdamW(discriminator.parameters(), 
                               lr=1e-5,  # è¿›ä¸€æ­¥é™ä½åˆ° 1e-5
                               weight_decay=1e-5)
    
    # ============ æŸå¤±å‡½æ•° ============
    criterion_GAN = GANLoss(gan_mode='lsgan').to(device)  # LSGAN æ›´ç¨³å®š
    
    # ============ å­¦ä¹ ç‡è°ƒåº¦å™¨ ============
    scheduler_G = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer_G, mode='min', factor=0.5, patience=10, verbose=True
    )
    scheduler_D = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer_D, mode='min', factor=0.5, patience=10, verbose=True
    )
    
    early_stopping = EarlyStopping(
        patience=50, 
        verbose=True, 
        path=os.path.join(model_fold_path, 'best_model.pt')
    )

    # ============ CSV æ—¥å¿— ============
    csv_filename = os.path.join(train_args.save_path, 'training_losses.csv')
    with open(csv_filename, 'w', newline='') as csvfile:
        fieldnames = [
            'Epoch', 'Train Recon Loss', 'Train Latent Trans Loss', 'Train Latent Dist Loss',
            'Train GAN Loss', 'Train D Loss', 'Train Total Loss', 'Train Sparsity',
            'Val Recon Loss', 'Val Latent Trans Loss', 'Val Latent Dist Loss',
            'Val GAN Loss', 'Val Total Loss', 'Val Sparsity', 
            'LR Generator', 'LR Discriminator'
        ]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

    print("\nğŸš€ å¼€å§‹è®­ç»ƒ (å…¨æ¨¡å‹å¾®è°ƒ + GAN)...\n")
    
    # ============ è®­ç»ƒå¾ªç¯ ============
    for epoch in range(train_args.epochs):
        model.train()
        discriminator.train()
        
        train_losses = {
            "latent_dist": 0, 
            "latent_trans": 0, 
            "recon": 0, 
            "gan": 0,
            "d_loss": 0,
            "total": 0, 
            "sparsity": 0
        }
        
        w = get_weights(epoch)
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{train_args.epochs}", ncols=120)
        for satellite, vil in pbar:
            satellite, vil = satellite.to(device), vil.to(device)
            bs = satellite.size(0)
            
            # ==================== æ›´æ–°åˆ¤åˆ«å™¨ ====================
            optimizer_D.zero_grad()
            
            # ç”Ÿæˆå‡å›¾åƒ
            with torch.no_grad():
                x_recon_trans, z, _, _, _, _ = model(satellite, vil)
            
            # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰å½¢çŠ¶ä¿¡æ¯ï¼ˆä»…ç¬¬ä¸€ä¸ª batchï¼‰
            if epoch == 0 and bs == satellite.size(0):  # ç¬¬ä¸€ä¸ªå®Œæ•´ batch
                print(f"\n{'='*60}")
                print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ (Epoch {epoch+1}, åˆ¤åˆ«å™¨è¾“å…¥)")
                print(f"{'='*60}")
                print(f"satellite shape:     {satellite.shape}")
                print(f"vil shape:           {vil.shape}")
                print(f"x_recon_trans shape: {x_recon_trans.shape}")
                print(f"vil is 5D?           {len(vil.shape) == 5}")
                print(f"x_recon_trans is 5D? {len(x_recon_trans.shape) == 5}")
            
            # å¤„ç†å¤šå¸§ï¼šå±•å¹³æ—¶é—´ç»´åº¦
            if len(vil.shape) == 5:  # [B, C, H, W, T]
                B, C, H, W, T = vil.size()
                vil_flat = vil.permute(0, 4, 1, 2, 3).contiguous().view(B * T, C, H, W)  # [B*T, C, H, W]
                
                # x_recon_trans å·²ç»æ˜¯ [B, T, C, H, W] æ ¼å¼ï¼Œç›´æ¥ reshape
                if len(x_recon_trans.shape) == 5:
                    B_r, T_r, C_r, H_r, W_r = x_recon_trans.size()  # æ³¨æ„é¡ºåºï¼
                    x_recon_flat = x_recon_trans.contiguous().view(B_r * T_r, C_r, H_r, W_r)
                else:
                    x_recon_flat = x_recon_trans
                    
                if epoch == 0 and bs == satellite.size(0):
                    print(f"\nè½¬æ¢å:")
                    print(f"vil_flat shape:      {vil_flat.shape}")
                    print(f"x_recon_flat shape:  {x_recon_flat.shape}")
                    print(f"{'='*60}\n")
            else:
                vil_flat = vil
                x_recon_flat = x_recon_trans
            
            # åˆ¤åˆ«çœŸå®å›¾åƒ
            pred_real = discriminator(vil_flat)
            loss_D_real = criterion_GAN(pred_real, target_is_real=True)
            
            # åˆ¤åˆ«å‡å›¾åƒ
            pred_fake = discriminator(x_recon_flat.detach())
            loss_D_fake = criterion_GAN(pred_fake, target_is_real=False)
            
            # åˆ¤åˆ«å™¨æ€»æŸå¤±
            loss_D = (loss_D_real + loss_D_fake) * 0.5
            loss_D.backward()
            optimizer_D.step()
            
            # ==================== æ›´æ–°ç”Ÿæˆå™¨ ====================
            optimizer_G.zero_grad()
            
            # ç”Ÿæˆå›¾åƒå¹¶è®¡ç®—æ‰€æœ‰æŸå¤±
            x_recon_trans, z, latent_dist_loss, latent_trans_loss, recon_loss, dictionary = model(satellite, vil)
            
            # GAN loss: æ¬ºéª—åˆ¤åˆ«å™¨
            if len(x_recon_trans.shape) == 5:  # x_recon_trans æ˜¯ [B, T, C, H, W]
                B, T, C, H, W = x_recon_trans.size()
                x_recon_flat = x_recon_trans.contiguous().view(B * T, C, H, W)
            else:
                x_recon_flat = x_recon_trans
            
            pred_fake = discriminator(x_recon_flat)
            loss_GAN = criterion_GAN(pred_fake, target_is_real=True)
            
            # ç”Ÿæˆå™¨æ€»æŸå¤±
            loss_G = (w["recon"] * recon_loss +
                     0.3 * latent_dist_loss +
                     w["trans"] * latent_trans_loss +
                     w["gan"] * loss_GAN)
            
            loss_G.backward()
            optimizer_G.step()
            
            # è®¡ç®—ç¨€ç–åº¦
            sparsity_loss = hoyer_metric(z)
            
            # ç´¯ç§¯æŸå¤±
            train_losses["latent_dist"] += latent_dist_loss.item() * bs
            train_losses["latent_trans"] += latent_trans_loss.item() * bs
            train_losses["recon"] += recon_loss.item() * bs
            train_losses["gan"] += loss_GAN.item() * bs
            train_losses["d_loss"] += loss_D.item() * bs
            train_losses["total"] += loss_G.item() * bs
            train_losses["sparsity"] += sparsity_loss.item() * bs
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'G': f'{loss_G.item():.4f}',
                'D': f'{loss_D.item():.4f}',
                'GAN': f'{loss_GAN.item():.3f}',
                'Recon': f'{recon_loss.item():.4f}'
            })
        
        # å¹³å‡è®­ç»ƒæŸå¤±
        for key in train_losses:
            train_losses[key] /= train_image_num
        
        # ==================== éªŒè¯ ====================
        model.eval()
        discriminator.eval()
        
        val_losses = {
            "latent_dist": 0, 
            "latent_trans": 0, 
            "recon": 0, 
            "gan": 0,
            "total": 0, 
            "sparsity": 0
        }
        
        with torch.no_grad():
            for satellite, vil in val_loader:
                satellite, vil = satellite.to(device), vil.to(device)
                bs = satellite.size(0)
                
                x_recon_trans, z, latent_dist_loss, latent_trans_loss, recon_loss, dictionary = model(satellite, vil)
                
                # GAN loss
                if len(x_recon_trans.shape) == 5:  # x_recon_trans æ˜¯ [B, T, C, H, W]
                    B, T, C, H, W = x_recon_trans.size()
                    x_recon_flat = x_recon_trans.contiguous().view(B * T, C, H, W)
                else:
                    x_recon_flat = x_recon_trans
                
                pred_fake = discriminator(x_recon_flat)
                loss_GAN = criterion_GAN(pred_fake, target_is_real=True)
                
                loss = (w["recon"] * recon_loss +
                       0.3 * latent_dist_loss +
                       w["trans"] * latent_trans_loss +
                       w["gan"] * loss_GAN)
                
                sparsity_loss = hoyer_metric(z)
                
                val_losses["latent_dist"] += latent_dist_loss.item() * bs
                val_losses["latent_trans"] += latent_trans_loss.item() * bs
                val_losses["recon"] += recon_loss.item() * bs
                val_losses["gan"] += loss_GAN.item() * bs
                val_losses["total"] += loss.item() * bs
                val_losses["sparsity"] += sparsity_loss.item() * bs
        
        for key in val_losses:
            val_losses[key] /= val_image_num
        
        # ==================== è®°å½•æ—¥å¿— ====================
        with open(csv_filename, 'a', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writerow({
                'Epoch': epoch + 1,
                'Train Recon Loss': train_losses['recon'],
                'Train Latent Trans Loss': train_losses['latent_trans'],
                'Train Latent Dist Loss': train_losses['latent_dist'],
                'Train GAN Loss': train_losses['gan'],
                'Train D Loss': train_losses['d_loss'],
                'Train Total Loss': train_losses['total'],
                'Train Sparsity': train_losses['sparsity'],
                'Val Recon Loss': val_losses['recon'],
                'Val Latent Trans Loss': val_losses['latent_trans'],
                'Val Latent Dist Loss': val_losses['latent_dist'],
                'Val GAN Loss': val_losses['gan'],
                'Val Total Loss': val_losses['total'],
                'Val Sparsity': val_losses['sparsity'],
                'LR Generator': get_lrs(optimizer_G),
                'LR Discriminator': get_lrs(optimizer_D)[0]
            })
        
        # æ‰“å°æ‘˜è¦
        print(f"\nEpoch {epoch+1} Summary:")
        print(f"  Train - Total: {train_losses['total']:.5f} | Recon: {train_losses['recon']:.5f} | GAN: {train_losses['gan']:.4f} | D: {train_losses['d_loss']:.4f}")
        print(f"  Val   - Total: {val_losses['total']:.5f} | Recon: {val_losses['recon']:.5f} | GAN: {val_losses['gan']:.4f}")
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler_G.step(val_losses['total'])
        scheduler_D.step(train_losses['d_loss'])
        
        # Early stopping
        early_stopping(val_losses['total'], model)
        
        if early_stopping.early_stop:
            print("\nğŸ›‘ Early stopping triggered. Loading best model...")
            model.load_state_dict(torch.load(early_stopping.path), strict=False)
            break
        
        # å®šæœŸä¿å­˜
        if (epoch + 1) % train_args.save_frequency == 0:
            plot_dict(dictionary, dict_fold_path, f'dictionary{epoch + 1:d}.png')
            torch.save(model.state_dict(), os.path.join(model_fold_path, f'model{epoch + 1:d}.pt'))
            torch.save(discriminator.state_dict(), os.path.join(model_fold_path, f'discriminator{epoch + 1:d}.pt'))
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-c', '--config', type=str, required=True, help='Path to config JSON')
    args = parser.parse_args()

    with open(args.config, 'r') as f:
        config = json.load(f)
    data_args = SimpleNamespace(**config['data'])
    model_args = SimpleNamespace(**config['model'])
    train_args = SimpleNamespace(**config['train'])
    test_args = SimpleNamespace(**config['test'])

    train(data_args, model_args, train_args, test_args)

