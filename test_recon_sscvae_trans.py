import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms

import os
import argparse
import json
from types import SimpleNamespace
import csv
import numpy as np
from utils.utils import MNISTDataset,GrayDataset, UltrasoundDataset, MiniImagenet, hoyer_metric, compute_indicators, slice_image, recon_image
from models import SSCVAE
from visualization import plot_images, plot_dict_tsne
from data import SevirTimeTransDataset

'''hyperparameters'''
parser = argparse.ArgumentParser(description='program args')
parser.add_argument('-c', '--config', type=str, required=True, help='config file path')
args = parser.parse_args()
with open(args.config, 'r') as json_data:
    config_data = json.load(json_data)
data_args = SimpleNamespace(**config_data['data'])
model_args = SimpleNamespace(**config_data['model'])
train_args = SimpleNamespace(**config_data['train'])
test_args = SimpleNamespace(**config_data['test'])


'''make dir'''
model_fold_path = os.path.join(train_args.save_path, 'models')
image_fold_path = os.path.join(train_args.save_path, 'images')


'''dataset'''
data_transform = {
    "test": transforms.Compose([])
}

if data_args.dataset == 'sevir':
    test_dataset = SevirTimeTransDataset(root_dir=data_args.root_dir,
                                 mode="test",
                                 transform=data_transform["test"])
else:
    raise ValueError("dataset: {} isn't allowed.".format(data_args.dataset))

test_loader = DataLoader(test_dataset,
                         batch_size=1,
                         shuffle=False,
                         pin_memory=True)

test_image_num = len(test_dataset)
#print("test_image_num:", test_image_num)


'''model'''
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# âœ… å¯ç”¨æ—¶é—´æ³¨æ„åŠ›ä»¥æ”¯æŒ LISTA temporal å¾®è°ƒåçš„æ¨¡å‹
model = SSCVAE(**vars(model_args), device=device, use_time_attention=True).to(device)

# ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
load_path = os.path.join(model_fold_path, f'best_model.pt')
print(f"ğŸ“‚ åŠ è½½æ¨¡å‹æƒé‡: {load_path}")

if not os.path.exists(load_path):
    raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {load_path}")

model.load_state_dict(torch.load(load_path, map_location=device), strict=False)  # strict=False å¿½ç•¥å¤šä½™æˆ–ç¼ºå¤±çš„é”®
model.eval()
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè¿›å…¥è¯„ä¼°æ¨¡å¼")


'''test'''
csv_filename = os.path.join(train_args.save_path, 'testing_indicators.csv')
print(f"ğŸ“Š æµ‹è¯•ç»“æœå°†ä¿å­˜åˆ°: {csv_filename}")

with open(csv_filename, 'w', newline='') as csvfile:
    fieldnames = ['Name', 'Sparsity', 'PSNR', 'SSIM', 'NMI', 'LPIPS']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()

plot_dict = True
import numpy as np

# å®šä¹‰ä¿å­˜è·¯å¾„ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ï¼‰
PRED_PATH = os.path.join(train_args.save_path, "images", "reconstructed_images_single")
TRUE_PATH = os.path.join(train_args.save_path, "images", "true_images_single")

# åˆ›å»ºä¿å­˜è·¯å¾„çš„æ–‡ä»¶å¤¹ï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
os.makedirs(PRED_PATH, exist_ok=True)
os.makedirs(TRUE_PATH, exist_ok=True)
print(f"ğŸ“ é‡å»ºå›¾åƒä¿å­˜è·¯å¾„: {PRED_PATH}")
print(f"ğŸ“ çœŸå®å›¾åƒä¿å­˜è·¯å¾„: {TRUE_PATH}")

# # ç”¨np.saveæ›¿æ¢plot_imagesï¼Œä¿å­˜ä¸º.npyæ–‡ä»¶
# with torch.no_grad():
#     for batch_idx, (satellite, vil) in enumerate(test_loader):
#         satellite = satellite.to(device)
#         bs, _, _, _, T = satellite.shape
#         vil = vil.to(device)
#         bs, _, _, _, _ = vil.shape

#         x_recon_trans_bchwt, ex_trans_seq, latent_dist_loss, latent_trans_loss, reconstruction_loss, dictionary, sparsity_loss = model(satellite, vil)

#         if plot_dict:
#             plot_dict_tsne(dictionary, train_args.save_path, 'sscvae_tsne.png')
#             plot_dict = False

#         # åˆå§‹åŒ–å­˜å‚¨æ¯ä¸€å¸§çš„æŒ‡æ ‡
#         psnr_list, ssim_list, nmi_list, lpips_list = [], [], [], []
#         sparsity = 1

#         # é€å¸§è®¡ç®—æŒ‡æ ‡å¹¶å­˜å‚¨
#         for t in range(T):
#             # vil: [B, C, H, W, T], x_recon_trans_bchwt: [B, T, C, H, W]
#             PSNR, SSIM, NMI, LPIPS = compute_indicators(vil[:, :, :, :, t], x_recon_trans_bchwt[:, t, :, :, :])
#             psnr_list.append(PSNR)
#             ssim_list.append(SSIM)
#             nmi_list.append(NMI)
#             lpips_list.append(LPIPS)

#             # ä¿å­˜å›¾åƒä¸º.npyæ–‡ä»¶
#             # ä¿å­˜åŸå§‹å›¾åƒ (vil) åˆ° TRUE_PATH
#             np.save(os.path.join(TRUE_PATH, f"{batch_idx}_{t}_vil.npy"), vil[:, :, :, :, t].cpu().numpy())
#             # ä¿å­˜é‡å»ºå›¾åƒ (x_recon_trans_bchwt) åˆ° PRED_PATH
#             np.save(os.path.join(PRED_PATH, f"{batch_idx}_{t}_recon.npy"), x_recon_trans_bchwt[:, t, :, :, :].cpu().numpy())
#             print(batch_idx, t)

#         # è®¡ç®—å¹³å‡æŒ‡æ ‡
#         avg_psnr = torch.mean(torch.tensor(psnr_list))
#         avg_ssim = torch.mean(torch.tensor(ssim_list))
#         avg_nmi = torch.mean(torch.tensor(nmi_list))
#         avg_lpips = torch.mean(torch.tensor(lpips_list))

#         # å†™å…¥ç»“æœ
#         with open(csv_filename, 'a', newline='') as csvfile:
#             writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
#             writer.writerow({'Name': str(batch_idx),
#                              'Sparsity': sparsity,
#                              'PSNR': avg_psnr.item(),
#                              'SSIM': avg_ssim.item(),
#                              'NMI': avg_nmi.item(),
#                              'LPIPS': avg_lpips.item()})

with torch.no_grad():
    print(f"\nğŸš€ å¼€å§‹æµ‹è¯•ï¼Œå…± {test_image_num} ä¸ªæ ·æœ¬...")
    for batch_idx, (satellite, vil) in enumerate(test_loader):
        satellite = satellite.to(device)
        bs, _, _, _,T = satellite.shape
        vil  = vil.to(device)
        bs, _, _, _,_ = vil.shape

        x_recon_trans, z, latent_dist_loss, latent_trans_loss, reconstruction_loss, dictionary = model(satellite,vil)

        if plot_dict:
            plot_dict_tsne(dictionary, train_args.save_path, 'sscvae_tsne.png')
            plot_dict = False

        # åˆå§‹åŒ–å­˜å‚¨æ¯ä¸€å¸§çš„æŒ‡æ ‡
        psnr_list, ssim_list, nmi_list, lpips_list = [], [], [], []
        sparsity = 1

        # é€å¸§è®¡ç®—æŒ‡æ ‡å¹¶å­˜å‚¨
        for t in range(T):
            # vil: [B, C, H, W, T] -> [:, :, :, :, t] -> [B, C, H, W]
            # x_recon_trans_bchwt: [B, T, C, H, W] -> [:, t, :, :, :] -> [B, C, H, W]
            PSNR, SSIM, NMI, LPIPS = compute_indicators(vil[:, :, :, :, t], x_recon_trans[:, t, :, :, :])
            psnr_list.append(PSNR)
            ssim_list.append(SSIM)
            nmi_list.append(NMI)
            lpips_list.append(LPIPS)
            
            # ä¿å­˜å›¾åƒä¸º.npyæ–‡ä»¶
            # ä¿å­˜åŸå§‹å›¾åƒ (vil) å’Œé‡å»ºå›¾åƒ (x_recon_trans_bchwt) ä¸º.npyæ–‡ä»¶
            np.save(os.path.join(PRED_PATH, f"{batch_idx}_{t}_vil.npy"), vil[:, :, :, :, t].cpu().numpy())
            np.save(os.path.join(TRUE_PATH, f"{batch_idx}_{t}_recon.npy"), x_recon_trans[:, t, :, :, :].cpu().numpy())
            # plot_images(vil[:, :, :, :, t], x_recon_trans[:, t, :, :, :], image_fold_path, str(batch_idx)+'+'+str(t), channels=1)

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_psnr = torch.mean(torch.tensor(psnr_list))
        avg_ssim = torch.mean(torch.tensor(ssim_list))
        avg_nmi = torch.mean(torch.tensor(nmi_list))
        avg_lpips = torch.mean(torch.tensor(lpips_list))

        # å†™å…¥ç»“æœ
        with open(csv_filename, 'a', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writerow({'Name': str(batch_idx),
                             'Sparsity': sparsity,
                             'PSNR': avg_psnr.item(),
                             'SSIM': avg_ssim.item(),
                             'NMI': avg_nmi.item(),
                             'LPIPS': avg_lpips.item()})
        
        # æ¯å¤„ç†10ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡è¿›åº¦
        if (batch_idx + 1) % 10 == 0:
            print(f"  è¿›åº¦: {batch_idx + 1}/{test_image_num} | PSNR: {avg_psnr:.4f}, SSIM: {avg_ssim:.4f}")

print(f"\nâœ… æµ‹è¯•å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {csv_filename}")